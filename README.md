# COVID-19: evitando um poss√≠vel colapso nos sistemas de sa√∫de
---
Este projeto foi desenvolvido durante o **Bootcamp de *Data Science* Aplicada (Alura)**, no √∫ltimo m√≥dulo. Neste, vimos alguns t√≥picos como modelos de ***Machine Learning***, ***Cross-Validation***, ***Efeitos da Aleatoriedade ao dividir o DataFrame em treino e teste***, ***Tuning de Hiperpar√¢metros*** ***etc***. As aulas foram feitas em cima de um *Dataset* do *Kaggle*, disponibilizado pelo **Hospital S√≠rio-Liban√™s**.

Como desafio, foi requisitado um **modelo que prev√™ a admiss√£o de pacientes com COVID-19 para leitos de UTI**, ou seja, se a pessoa est√° em um risco maior por conta do novo coronav√≠rus, al√©m de realizar uma ***EDA*** dos dados.

- An√°lise completa em "**previsao_leitos_uti_sirio_libanes_otimizada.ipynb**".

Observa√ß√µes: 
- A primeira vers√£o deste projeto est√° [neste link](https://github.com/Emersonmiady/previsao-leitos-uti).

# Contexto
---
A pandemia da COVID-19 atingiu o mundo inteiro, sobrecarregando assim os sistemas de sa√∫de, os quais estavam despreparados para uma solicita√ß√£o t√£o intensa e demorada de leitos de UTI, profissionais, equipamentos de prote√ß√£o individual e recursos de sa√∫de.

![colapse](/img/colapse.jpg)

Acima vemos a curva **cinza** sendo o ideal, pois est√° abaixo da capacidade que o sistema est√° dispondo. Obviamente que, medidas como:

- **Lavar sempre as m√£os**;
- **Passar √°lcool em gel frequentemente e usar m√°scaras ao sair de casa**;
- **Se poss√≠vel, ainda adotar o isolamento social**.

Ajudam muito a reduzir esses aumentos de casos di√°rios, deixando a curva vermelha mais parecida com a situa√ß√£o que queremos. Entretanto, se essas n√£o forem seguidas, ter√≠amos que aumentar a capacidade dos sistemas de sa√∫de, e assim, exigindo verba e tempo at√© adquirir mais recursos m√©dicos.

Mas o que devemos fazer se a quantidade de leitos ficar est√°vel e n√£o existirem muitos equipamentos sobrando? √â a√≠ que nos deparamos com um outro problema, relacionado a **gest√£o de pessoas que v√£o para a UTI do pr√≥prio hospital:**

- Se encontrarmos uma situa√ß√£o em que todos os leitos est√£o ocupados, precisamos de **agilidade para evitar um poss√≠vel superlotamento do espa√ßo**, e al√©m disso, ter√≠amos que **transferir as pessoas para a UTI de outros hospitais**!
- Se determinado hospital estiver com leitos dispon√≠veis, poder√≠amos contatar os outros locais de sa√∫de para **transferir mais pessoas neste**.

Sendo assim, pensando na **necessidade de ser √°gil** para a ida e vinda de pacientes, o Hospital S√≠rio-Liban√™s est√° tentando buscar uma solu√ß√£o para o caso, isto √©, **prever se a pessoa precisar√° de leito antecipadamente**. E √© disso que se trata este projeto.

**Base de dados:** [Dataset do Hospital S√≠rio-Liban√™s (*Kaggle*)](https://www.kaggle.com/S%C3%ADrio-Libanes/covid19), com todas as features j√° *normalizadas*.

# Ferramentas utilizadas
---
- Linguagem de programa√ß√£o Python;
- Pacotes: `pandas`, `numpy`, `matplotlib`, `seaborn`, `plotly`, `IPython`, `warnings`, `boruta`, `sklearn`, `statsmodels` e `picke`;
- Notebook: *Jupyter Notebook*.

# Descri√ß√£o breve das etapas
---
## 1. Pr√©-processamento dos dados

### 1.1. Primeiro momento
- Preenchimento de valores faltantes com m√©todos "*backfill*" e "*fowardfill*" dado um mesmo paciente;
- Remo√ß√£o de pacientes que j√° s√£o declarados como `ICU` = 1 na primeira janela (`0-2`);
- Remo√ß√£o dos pacientes que n√£o foram coletadas nenhuma informa√ß√£o de certa vari√°vel em nenhuma das janelas;
- Sele√ß√£o de uma √∫nica janela de tempo (`0-2`).

### 1.2. Segundo momento
- Remo√ß√£o da maioria das vari√°veis que possuem `MIN`, `MAX` e `MEDIAN` no final.

### 1.3. Terceiro momento
- Sele√ß√£o de vari√°veis com o algoritmo `BorutaPy`, indo apenas para 8 vari√°veis independentes e 1 dependente (uma excelente evolu√ß√£o)!

## 2. An√°lise Explorat√≥ria dos Dados
Utilizei gr√°ficos de barras, *violinplots*, *boxplots*, matriz de correla√ß√£o (mapa de calor) e gr√°ficos de regress√£o. V√£o alguns exemplos de visualiza√ß√µes abaixo:

![age_percentil](/img/age_percentil.png)

![icu_age_above](/img/icu_age_above.png)

![gender](/img/gender.png)

![diseases](/img/diseases.png)

![blood_vital_signs](/img/blood_vital_signs.png)

![correlation_map](/img/correlation_map.png)

![regression_plots_high_corr](/img/regression_plots_high_corr.png)

## 3. Machine Learning: modelos testados
Foram testados:
- Naive-Bayes;
- Regress√£o Log√≠stica;
- √Årvore de Decis√£o;
- Random Forest.

## 4. Procedimento para saber qual deles √© o melhor
1. Divis√£o das vari√°veis em dependente (y) e independentes (X);
2. Cross-Validation com todo o *DataFrame*, calculando tamb√©m o intervalo de confian√ßa para os resultados (m√©tricas) dos modelos (o intervalo foi calculado pois existiam poucas linhas, podendo haver um vi√©s aleat√≥rio na divis√£o de treino e teste);
3. Avalia√ß√£o de todas as m√©tricas e sele√ß√£o do melhor modelo. Abaixo v√£o os resultados:

![metrics](/img/metrics.png)

Ap√≥s algumas an√°lises, a ***Random Forest Classifier*** foi a escolhida!

O que realmente pesou foi o melhor *Recall*, pois quanto menos falsos negativos tiver, ou seja, a pessoa n√£o ser admitida para UTI mas que na verdade era para ser, √© melhor. Um *Recall* ruim pode literalmente matar pessoas... Ent√£o basicamente optei tamb√©m pelo modelo com a melhor sensibilidade.

Apesar de j√° escolher o melhor modelo, resolvi olhar para os *betas* da regress√£o log√≠stica, porque tamb√©m indicam, de forma linear, as vari√°veis mais importantes para este modelo, e descobri que, o `PCR_MEAN` foi a mais importante, indicando que, quando √© aumentado em uma unidade nesta vari√°vel, a chance da pessoa precisar de UTI √© aumentada em  $ùëí^{2.96} \approx 20$ vezes! Para finalizar, fiz um paralelo com a *feature importances* do modelo da *Random Forest Classifier*, e a `PCR_MEAN` continuou sendo a mais importante!

![feature_importances_1](/img/feature_importances_1.png)

## 5. *Tuning* de Hiperpar√¢metros
Acabei testando no `GridSearchCV()` (fun√ß√£o do `sklearn`) valores diferentes para `max_features` e `n_estimators`. O resultado foi:

- `max_features`: 2;
- `n_estimators`: 100.

![train_cv_validation_recall](/img/train_cv_validation_recall.png)

## 6. Visualiza√ß√µes extras

- *Coutor plots* (2D e 3D), realizado com o `plotly`;

- *Feature Importances* final:

![feature_importances_2](/img/feature_importances_2.png)

## 7. Valida√ß√£o Final

Para finalizar com o notebook, realizei a valida√ß√£o final com os dados separados anteriormente, √© como se o modelo recebesse dados completamente novos. Na minha opini√£o, os resultados foram muito positivos, com um *recall* de 0.87 e *f1-score* de 0.79!

![confusion_matrix_final](/img/confusion_matrix_final.png)
